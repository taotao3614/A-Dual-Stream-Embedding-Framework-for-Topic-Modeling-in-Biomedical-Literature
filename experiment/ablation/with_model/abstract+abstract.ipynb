{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.representation import MaximalMarginalRelevance\n",
    "from hdbscan import HDBSCAN\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n",
    "from octis.evaluation_metrics.coherence_metrics import Coherence\n",
    "import pandas as pd\n",
    "from pymilvus import connections, utility, Collection, FieldSchema, CollectionSchema, DataType\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline           # Hugging Face转换器\n",
    "import networkx as nx                       # 网络图形可视化\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验说明：该实验使用和原本文献相同的超参数，在embedding时，使用了原本的abstract，模型采用了三中下述的不同模型。投入bertopic的文本为abstract。目的是验证embedding时候使用不同模型带来的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuML/pubmedbert-base-embeddings: TC = 0.5636, TD = 0.7125 \n",
    "### 'dmis-lab/biobert-v1.1': TC = 0.4765, TD = 0.6389\n",
    "### 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext':TC = 0.5000, TD = 0.6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据总量: 3000\n",
      "年份范围: 2002 - 2025\n"
     ]
    }
   ],
   "source": [
    "# 设置文件路径\n",
    "raw_csv_path =\"../raw.csv\"\n",
    "\n",
    "# 读取CSV文件\n",
    "def load_info():\n",
    "    # 读取csv文件\n",
    "    df = pd.read_csv(raw_csv_path)\n",
    "    \n",
    "    # 提取需要的列\n",
    "    info = []\n",
    "    for _, row in df.iterrows():\n",
    "        abstract = row['abstract']\n",
    "        try:\n",
    "            year = int(row['pub_year'])\n",
    "        except:\n",
    "            year = np.nan\n",
    "        # 这里只保留abstract和year，根据要求忽略doi, journal, citation\n",
    "        info.append([abstract, year, None, None, None])  # None占位符用于与原代码结构保持一致\n",
    "    \n",
    "    # 创建DataFrame，保持与原代码相同的列结构\n",
    "    info = pd.DataFrame(info, columns=['abstract', 'year', 'doi', 'journal', 'citation'])\n",
    "    return info\n",
    "\n",
    "# 加载数据\n",
    "data_full = load_info()\n",
    "\n",
    "# 移除缺失摘要的条目\n",
    "data_full = data_full.dropna(subset=['abstract'])\n",
    "\n",
    "# 提取摘要文本用于主题建模\n",
    "docs = data_full.abstract.values\n",
    "\n",
    "# 打印基本信息\n",
    "print(f\"数据总量: {len(data_full)}\")\n",
    "print(f\"年份范围: {data_full['year'].min()} - {data_full['year'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# # 初始化tokenizer (使用BERT基础模型，您也可以根据需要换成其他模型)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# # 计算docs中每条数据的token数量\n",
    "# token_counts = [len(tokenizer.encode(doc)) for doc in docs]\n",
    "\n",
    "# # 计算统计信息\n",
    "# total_tokens = sum(token_counts)\n",
    "# avg_tokens = total_tokens / len(docs)\n",
    "# max_tokens = max(token_counts)\n",
    "# min_tokens = min(token_counts)\n",
    "\n",
    "# # 打印结果\n",
    "# print(f\"总token数: {total_tokens}\")\n",
    "# print(f\"平均每条数据token数: {avg_tokens:.2f}\")\n",
    "# print(f\"最大token数: {max_tokens}\")\n",
    "# print(f\"最小token数: {min_tokens}\")\n",
    "# print(f\"超过512 token的数据比例: {sum(1 for x in token_counts if x > 512) / len(token_counts):.2%}\")\n",
    "# print(f\"超过1024 token的数据比例: {sum(1 for x in token_counts if x > 1024) / len(token_counts):.2%}\")\n",
    "\n",
    "# # 如果您想查看更详细的分布，取消下面的注释\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(token_counts, bins=50)\n",
    "# plt.title('Token数量分布')\n",
    "# plt.xlabel('Token数量')\n",
    "# plt.ylabel('文档数量')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name C:\\Users\\MSI/.cache\\torch\\sentence_transformers\\microsoft_BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at C:\\Users\\MSI/.cache\\torch\\sentence_transformers\\microsoft_BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# model instance\n",
    "embedding_model = SentenceTransformer(\n",
    "  # 'all-MiniLM-L6-v2',\n",
    "  # 'all-mpnet-base-v2',\n",
    "  'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext',\n",
    "  # 'dmis-lab/biobert-v1.1',\n",
    "  # 'NeuML/pubmedbert-base-embeddings',\n",
    ")\n",
    "\n",
    "# embeddings = np.load('data/emb-covid-19-pubmedbert-base-embeddings.npy')\n",
    "# print(type(embeddings), embeddings.shape)\n",
    "\n",
    "# reduce dimensionality\n",
    "umap_model = UMAP(\n",
    "    n_neighbors = 15, n_components = 5, min_dist = 0.0, \n",
    "    metric = 'cosine', random_state = 34)\n",
    "# cluster reduced embeddings\n",
    "hdbscan_model = HDBSCAN(\n",
    "    min_cluster_size = 30, min_samples = 10,  \n",
    "    metric = 'euclidean', cluster_selection_method = 'eom', \n",
    "    prediction_data = True)\n",
    "\n",
    "# tokenize topics\n",
    "vectorizer_model = CountVectorizer(stop_words = \"english\")\n",
    "# create topic representation\n",
    "ctfidf_model = ClassTfidfTransformer()\n",
    "# fine tune with relevance\n",
    "representation_model = MaximalMarginalRelevance(diversity = 0.2)\n",
    "# all steps together\n",
    "topic_model = BERTopic(\n",
    "  embedding_model = embedding_model,    # Step 1 - Extract embeddings\n",
    "  umap_model = umap_model,              # Step 2 - Reduce dimensionality\n",
    "  hdbscan_model = hdbscan_model,        # Step 3 - Cluster reduced embeddings\n",
    "  vectorizer_model = vectorizer_model,  # Step 4 - Tokenize topics\n",
    "  ctfidf_model = ctfidf_model,          # Step 5 - Extract topic words        \n",
    "  calculate_probabilities = True,        \n",
    "  verbose = True,\n",
    "  representation_model = representation_model # Diversify topic words\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4645c9b6bd443509913c0f49a4e7aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 12:53:38,683 - BERTopic - Transformed documents to Embeddings\n",
      "2025-05-07 12:53:50,585 - BERTopic - Reduced dimensionality\n",
      "2025-05-07 12:53:50,746 - BERTopic - Clustered reduced embeddings\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>677</td>\n",
       "      <td>-1_depression_self_symptoms_stress</td>\n",
       "      <td>[depression, self, symptoms, stress, participa...</td>\n",
       "      <td>[OBJECTIVE: The authors characterize medical s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>702</td>\n",
       "      <td>0_depression_anxiety_factors_stress</td>\n",
       "      <td>[depression, anxiety, factors, stress, prevale...</td>\n",
       "      <td>[BACKGROUND: Coronavirus disease 2019 (COVID-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>262</td>\n",
       "      <td>1_support_methods_training_university</td>\n",
       "      <td>[support, methods, training, university, nursi...</td>\n",
       "      <td>[AIM: To evaluate healthcare professional (HCP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>207</td>\n",
       "      <td>2_nursing_experiences_education_faculty</td>\n",
       "      <td>[nursing, experiences, education, faculty, tra...</td>\n",
       "      <td>[Research has revealed the effectiveness of si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>194</td>\n",
       "      <td>3_validity_reliability_psychometric_properties</td>\n",
       "      <td>[validity, reliability, psychometric, properti...</td>\n",
       "      <td>[BACKGROUND: The 30-item USDI is a self-report...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>149</td>\n",
       "      <td>4_intervention_control_participants_groups</td>\n",
       "      <td>[intervention, control, participants, groups, ...</td>\n",
       "      <td>[BACKGROUND: Psychoeducation has turned into a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>147</td>\n",
       "      <td>5_depression_patients_outcomes_symptoms</td>\n",
       "      <td>[depression, patients, outcomes, symptoms, res...</td>\n",
       "      <td>[IMPORTANCE: Addressing physician suicide requ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>128</td>\n",
       "      <td>6_drinking_alcohol_college_symptoms</td>\n",
       "      <td>[drinking, alcohol, college, symptoms, anxiety...</td>\n",
       "      <td>[OBJECTIVE: In college student samples, the as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "      <td>7_college_depression_survey_drug</td>\n",
       "      <td>[college, depression, survey, drug, substance,...</td>\n",
       "      <td>[BACKGROUND: A considerable gap in knowledge e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>103</td>\n",
       "      <td>8_residents_residency_resident_training</td>\n",
       "      <td>[residents, residency, resident, training, pro...</td>\n",
       "      <td>[BACKGROUND: Burnout is a syndrome of emotiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>88</td>\n",
       "      <td>9_symptoms_stress_patients_depression</td>\n",
       "      <td>[symptoms, stress, patients, depression, life,...</td>\n",
       "      <td>[INTRODUCTION: Data on the mental health of un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>75</td>\n",
       "      <td>10_anxiety_symptoms_avoidance_participants</td>\n",
       "      <td>[anxiety, symptoms, avoidance, participants, m...</td>\n",
       "      <td>[BACKGROUND AND OBJECTIVES: Anxiety sensitivit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>56</td>\n",
       "      <td>11_mindfulness_participants_program_treatment</td>\n",
       "      <td>[mindfulness, participants, program, treatment...</td>\n",
       "      <td>[This study evaluated the efficacy of Internet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>53</td>\n",
       "      <td>12_intervention_treatment_icbt_university</td>\n",
       "      <td>[intervention, treatment, icbt, university, ba...</td>\n",
       "      <td>[BACKGROUND: Emerging adulthood is often assoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>52</td>\n",
       "      <td>13_covid_college_participants_depression</td>\n",
       "      <td>[covid, college, participants, depression, sym...</td>\n",
       "      <td>[In March 2020, New York City (NYC) experience...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                            Name  \\\n",
       "0      -1    677              -1_depression_self_symptoms_stress   \n",
       "1       0    702             0_depression_anxiety_factors_stress   \n",
       "2       1    262           1_support_methods_training_university   \n",
       "3       2    207         2_nursing_experiences_education_faculty   \n",
       "4       3    194  3_validity_reliability_psychometric_properties   \n",
       "5       4    149      4_intervention_control_participants_groups   \n",
       "6       5    147         5_depression_patients_outcomes_symptoms   \n",
       "7       6    128             6_drinking_alcohol_college_symptoms   \n",
       "8       7    107                7_college_depression_survey_drug   \n",
       "9       8    103         8_residents_residency_resident_training   \n",
       "10      9     88           9_symptoms_stress_patients_depression   \n",
       "11     10     75      10_anxiety_symptoms_avoidance_participants   \n",
       "12     11     56   11_mindfulness_participants_program_treatment   \n",
       "13     12     53       12_intervention_treatment_icbt_university   \n",
       "14     13     52        13_covid_college_participants_depression   \n",
       "\n",
       "                                       Representation  \\\n",
       "0   [depression, self, symptoms, stress, participa...   \n",
       "1   [depression, anxiety, factors, stress, prevale...   \n",
       "2   [support, methods, training, university, nursi...   \n",
       "3   [nursing, experiences, education, faculty, tra...   \n",
       "4   [validity, reliability, psychometric, properti...   \n",
       "5   [intervention, control, participants, groups, ...   \n",
       "6   [depression, patients, outcomes, symptoms, res...   \n",
       "7   [drinking, alcohol, college, symptoms, anxiety...   \n",
       "8   [college, depression, survey, drug, substance,...   \n",
       "9   [residents, residency, resident, training, pro...   \n",
       "10  [symptoms, stress, patients, depression, life,...   \n",
       "11  [anxiety, symptoms, avoidance, participants, m...   \n",
       "12  [mindfulness, participants, program, treatment...   \n",
       "13  [intervention, treatment, icbt, university, ba...   \n",
       "14  [covid, college, participants, depression, sym...   \n",
       "\n",
       "                                  Representative_Docs  \n",
       "0   [OBJECTIVE: The authors characterize medical s...  \n",
       "1   [BACKGROUND: Coronavirus disease 2019 (COVID-1...  \n",
       "2   [AIM: To evaluate healthcare professional (HCP...  \n",
       "3   [Research has revealed the effectiveness of si...  \n",
       "4   [BACKGROUND: The 30-item USDI is a self-report...  \n",
       "5   [BACKGROUND: Psychoeducation has turned into a...  \n",
       "6   [IMPORTANCE: Addressing physician suicide requ...  \n",
       "7   [OBJECTIVE: In college student samples, the as...  \n",
       "8   [BACKGROUND: A considerable gap in knowledge e...  \n",
       "9   [BACKGROUND: Burnout is a syndrome of emotiona...  \n",
       "10  [INTRODUCTION: Data on the mental health of un...  \n",
       "11  [BACKGROUND AND OBJECTIVES: Anxiety sensitivit...  \n",
       "12  [This study evaluated the efficacy of Internet...  \n",
       "13  [BACKGROUND: Emerging adulthood is often assoc...  \n",
       "14  [In March 2020, New York City (NYC) experience...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练模型\n",
    "topics, probs = topic_model.fit_transform(docs)\n",
    "\n",
    "# topic_model.fit_transform(docs, embeddings=embeddings)\n",
    "\n",
    "# 获取聚类结果\n",
    "topic_info = topic_model.get_topic_info()\n",
    "topic_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info about all docs assigned to topics\n",
    "documents = topic_model.get_document_info(docs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TC = 0.5000, TD = 0.6000\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# 模块5: 模型评估\n",
    "# 计算主题一致性(TC)和主题多样性(TD)指标\n",
    "# ====================================\n",
    "# 将每个主题下的文档合并为一个长文档\n",
    "documents_per_topic = documents.groupby(['Topic'], as_index = False).agg({'Document': ' '.join})\n",
    "# 对文档进行预处理\n",
    "cleaned_docs = topic_model._preprocess_text(documents_per_topic.Document.values)\n",
    "# 构建文档分析器\n",
    "analyzer = topic_model.vectorizer_model.build_analyzer()\n",
    "# 获取每个文档的标记\n",
    "tokens = [analyzer(doc) for doc in cleaned_docs]\n",
    "# 构建主题词列表(每个主题取前10个关键词的第一个元素)\n",
    "bertopic_topics = [\n",
    "    [topicwords[0] for topicwords in topic_model.get_topic(i)[:10]]\n",
    "    for i in range(len(set(topics)) - 1)]\n",
    "# 计算主题一致性(Topic Coherence)\n",
    "TC = Coherence(texts = tokens, topk = 10, measure = 'c_v').score({'topics': bertopic_topics}) \n",
    "# 计算主题多样性(Topic Diversity)\n",
    "TD = TopicDiversity().score({'topics': bertopic_topics})\n",
    "# print('TC = ', TC, 'TD = ', TD)\n",
    "# 输出保留4位小数的指标值\n",
    "print(f'TC = {TC:.4f}, TD = {TD:.4f}')\n",
    "\n",
    "\n",
    "# TC = 0.6345, TD = 0.6741 covid\n",
    "\n",
    "# TC = 0.5814, TD = 0.7824 depression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ====================================\n",
    "# # 模块6: 主题探索和分析\n",
    "# # 对特定主题进行详细分析\n",
    "# # ====================================\n",
    "# # 选择一个感兴趣的主题进行分析\n",
    "# MY_TOPIC = 5\n",
    "# # 获取该主题的十个关键词\n",
    "# topic_model.get_topic(MY_TOPIC) \n",
    "# # 获取分配给该主题的所有文档\n",
    "# assigned_docs = documents[documents.Topic == MY_TOPIC] \n",
    "# # 打印该主题下所有文档的摘要\n",
    "# for abstract in assigned_docs.Document:\n",
    "#     print(abstract)\n",
    "#     print('---')\n",
    "\n",
    "# # 获取该主题的代表性文档\n",
    "# representative_docs = topic_model.get_representative_docs(MY_TOPIC)\n",
    "# # 获取代表性文档的引用信息\n",
    "# data_full[data_full.abstract == representative_docs[1]].iloc[0].citation\n",
    "    \n",
    "# # 使用零样本分类器为主题分配标签\n",
    "# classifier = pipeline(\"zero-shot-classification\", model = \"facebook/bart-large-mnli\")\n",
    "# # 将主题关键词组合成一个序列\n",
    "# sequence_to_classify =  \" \".join([word for word, _ in topic_model.get_topic(MY_TOPIC)])\n",
    "# # 定义候选标签\n",
    "# candidate_labels = [\"Psychometrics of depression\"]\n",
    "# # 执行分类\n",
    "# classifier(sequence_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ====================================\n",
    "# # 模块7: 结果可视化\n",
    "# # 使用多种方法可视化主题建模结果\n",
    "# # ====================================\n",
    "# # 1. 条形图 - 显示前六个主题的关键词\n",
    "# barchart = topic_model.visualize_barchart(top_n_topics = 6, n_words = 5, width = 400, title = \"\")\n",
    "# barchart.show()\n",
    "\n",
    "# # 2. 主题间关系图 - 展示主题之间的距离和关系\n",
    "# topic_model.visualize_topics().show()\n",
    "\n",
    "# # 3. 热力图 - 显示主题之间的相似度矩阵\n",
    "# topic_model.visualize_heatmap(n_clusters = 7)\n",
    "\n",
    "# # 4. 层次聚类 - 展示主题的层次结构\n",
    "# hierarchical_topics = topic_model.hierarchical_topics(docs)\n",
    "# topic_model.visualize_hierarchy(hierarchical_topics = hierarchical_topics)\n",
    "\n",
    "# # 5. 文档嵌入可视化 - 展示文档在空间中的分布\n",
    "# embeddings = embedding_model.encode(docs, show_progress_bar = False)\n",
    "# topic_model.visualize_documents(docs, embeddings = embeddings)   \n",
    "# topic_model.visualize_hierarchical_documents(docs, hierarchical_topics, embeddings = embeddings) \n",
    " \n",
    "# # 6. 时间序列分析 - 展示主题随时间变化的趋势\n",
    "# time = data_full.year.to_list() \n",
    "# topics_over_time = topic_model.topics_over_time(docs, time)\n",
    "# topic_model.visualize_topics_over_time(topics_over_time, topics = [0, 4, 5, 20])\n",
    "\n",
    "# # 7. 主题相关性搜索 - 查找与特定关键词相关的主题\n",
    "# # 函数：绘制关键词与主题的相似度网络图\n",
    "# def draw_simil(keyword):\n",
    "#     # 找出与关键词最相关的3个主题及其相似度\n",
    "#     topicsF, similarity = topic_model.find_topics(keyword, top_n = 3)\n",
    "#     # 构建网络图的节点\n",
    "#     G = nx.DiGraph()\n",
    "#     G.add_node(-1)\n",
    "#     G.add_node(0)\n",
    "#     G.add_node(1)\n",
    "#     G.add_node(2)\n",
    "#     node_labels = dict(enumerate(topicsF))\n",
    "#     node_labels[-1] = keyword\n",
    "#     scale = (len(keyword) + 12) * 0.032\n",
    "#     x_offset = 0.25 * scale\n",
    "#     y_offset = -.5\n",
    "#     # 设置节点位置\n",
    "#     pos = {\n",
    "#         -1: (0, 0),\n",
    "#         0: (-x_offset * scale, y_offset),\n",
    "#         1: (0, y_offset),\n",
    "#         2: (x_offset * scale, y_offset)\n",
    "#     }\n",
    "#     # 绘制节点\n",
    "#     nx.draw(\n",
    "#         G, pos = pos, labels = node_labels, with_labels = True, node_shape = \"s\", \n",
    "#         bbox = dict(facecolor = \"lightgreen\", edgecolor = 'black', boxstyle = 'round,pad=0.5'))\n",
    "    \n",
    "#     # 构建边的图形(用于改变边的位置)\n",
    "#     H = nx.DiGraph()\n",
    "#     for i, sim_val in enumerate(similarity):\n",
    "#         H.add_edge(i + 3, i, label = round(sim_val, 2)) # 3->0, 4->1, 5->2\n",
    "#     y_offset = -.48\n",
    "#     # 设置边位置\n",
    "#     pos = {\n",
    "#         0: (-x_offset * scale, y_offset),\n",
    "#         1: (0, y_offset),\n",
    "#         2: (x_offset * scale, y_offset),\n",
    "#         3: (-x_offset * scale, 0),\n",
    "#         4: (0, 0),\n",
    "#         5: (x_offset * scale, 0)\n",
    "#     }\n",
    "#     edge_labels = nx.get_edge_attributes(H, \"label\")\n",
    "#     # 绘制边和标签\n",
    "#     nx.draw_networkx(H, labels = {}, node_color = \"white\", arrows = True, pos = pos)\n",
    "#     nx.draw_networkx_edge_labels(H, pos, edge_labels)\n",
    "#     # 设置图形边距\n",
    "#     plt.xlim(-1, 1)\n",
    "#     plt.ylim(-1, 1)\n",
    "#     ax = plt.gca()\n",
    "#     ax.margins(0.20)\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.show()\n",
    "\n",
    "# # 分析两个关键词与主题的相关性\n",
    "# draw_simil('internet addiction')\n",
    "# draw_simil('burnout measures')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bertopic-tut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
